

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Methods &mdash; classeval classeval documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/language_data.js"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Eval" href="Plots.html" />
    <link rel="prev" title="Quickstart" href="Installation.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home"> classeval
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Installation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="Installation.html">Quickstart</a></li>
<li class="toctree-l1"><a class="reference internal" href="Installation.html#installation">Installation</a></li>
</ul>
<p class="caption"><span class="caption-text">Methods</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">Methods</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#two-class-approach">Two-class approach</a></li>
<li class="toctree-l2"><a class="reference internal" href="#multi-class-approach">Multi-class approach</a></li>
<li class="toctree-l2"><a class="reference internal" href="#optimizing-model-performance">Optimizing model performance</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="#evaluation-methods">Evaluation methods</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#confusion-matrix">Confusion matrix</a></li>
<li class="toctree-l2"><a class="reference internal" href="#roc-auc">ROC-AUC</a></li>
<li class="toctree-l2"><a class="reference internal" href="#cap">CAP</a></li>
<li class="toctree-l2"><a class="reference internal" href="#average-precision-ap">Average Precision (AP)</a></li>
<li class="toctree-l2"><a class="reference internal" href="#f1-score">F1-score</a></li>
<li class="toctree-l2"><a class="reference internal" href="#kappa">Kappa</a></li>
<li class="toctree-l2"><a class="reference internal" href="#mcc">MCC</a></li>
</ul>
</li>
</ul>
<p class="caption"><span class="caption-text">Plots</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="Plots.html">Eval</a></li>
<li class="toctree-l1"><a class="reference internal" href="Plots.html#roc-auc">ROC-AUC</a></li>
<li class="toctree-l1"><a class="reference internal" href="Plots.html#cap">CAP</a></li>
<li class="toctree-l1"><a class="reference internal" href="Plots.html#ap">AP</a></li>
<li class="toctree-l1"><a class="reference internal" href="Plots.html#confusion-matrix">Confusion matrix</a></li>
<li class="toctree-l1"><a class="reference internal" href="Plots.html#probability-plot">Probability Plot</a></li>
</ul>
<p class="caption"><span class="caption-text">Examples</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="Examples.html">Examples two-class model</a></li>
<li class="toctree-l1"><a class="reference internal" href="Examples.html#examples-multi-class-model">Examples multi-class model</a></li>
<li class="toctree-l1"><a class="reference internal" href="Examples.html#model-performance-tweaking">Model Performance tweaking</a></li>
</ul>
<p class="caption"><span class="caption-text">Code Documentation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="Coding quality.html">Coding quality</a></li>
<li class="toctree-l1"><a class="reference internal" href="classeval.classeval.html">API References</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">classeval</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html">Docs</a> &raquo;</li>
        
      <li>Methods</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/Methods.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <hr class="docutils" id="code-directive" />
<div class="section" id="methods">
<h1>Methods<a class="headerlink" href="#methods" title="Permalink to this headline">¶</a></h1>
<p>The <code class="docutils literal notranslate"><span class="pre">classeval</span></code> library contains various measures to estimate the models performance.
The main function to evaluated models performance is the function <a class="reference internal" href="classeval.classeval.html#classeval.classeval.eval" title="classeval.classeval.eval"><code class="xref py py-func docutils literal notranslate"><span class="pre">classeval.classeval.eval()</span></code></a>.
This function automatically determines whether your trained model is based on a <strong>two-class</strong> or <strong>multi-class</strong> approach.</p>
<div class="section" id="two-class-approach">
<h2>Two-class approach<a class="headerlink" href="#two-class-approach" title="Permalink to this headline">¶</a></h2>
<p>Two-class models are trained on two classes; the class-of-interest versus the rest-class. Such approach is commonly used across image-recognition, network-analysis, sensor data or any other type of data.
The <a class="reference internal" href="classeval.classeval.html#classeval.classeval.eval" title="classeval.classeval.eval"><code class="xref py py-func docutils literal notranslate"><span class="pre">classeval.classeval.eval()</span></code></a> function requires three input parameters. It is also possible to directly use the two-class function <a class="reference internal" href="classeval.classeval.html#classeval.classeval.eval_twoclass" title="classeval.classeval.eval_twoclass"><code class="xref py py-func docutils literal notranslate"><span class="pre">classeval.classeval.eval_twoclass()</span></code></a>, the outputs are identical.</p>
<dl class="simple">
<dt>Parameters required</dt><dd><ul class="simple">
<li><p>y_true : The true class label</p></li>
<li><p>y_proba : Probability of the predicted class label</p></li>
<li><p>y_pred : Predicted class label</p></li>
</ul>
</dd>
</dl>
</div>
<div class="section" id="multi-class-approach">
<h2>Multi-class approach<a class="headerlink" href="#multi-class-approach" title="Permalink to this headline">¶</a></h2>
<p>Multi-class models are trained on… Yes, multiple classes. These models are often used in textmining where the number of classes are high as these usually represent various textual catagories.
A disadvantage of multi-class models is a higher model complexity and many generic performance statistics can not be used.
The <a class="reference internal" href="classeval.classeval.html#classeval.classeval.eval" title="classeval.classeval.eval"><code class="xref py py-func docutils literal notranslate"><span class="pre">classeval.classeval.eval()</span></code></a> function requires three input parameters. It is also possible to directly use the <a class="reference internal" href="classeval.classeval.html#classeval.classeval.eval_multiclass" title="classeval.classeval.eval_multiclass"><code class="xref py py-func docutils literal notranslate"><span class="pre">classeval.classeval.eval_multiclass()</span></code></a>. Here, the outputs are also identifical.</p>
<dl class="simple">
<dt>Parameters required</dt><dd><ul class="simple">
<li><p>y_true : The true class label</p></li>
<li><p>y_proba : Probability of the predicted class label</p></li>
<li><p>y_score : Model decision function</p></li>
</ul>
</dd>
</dl>
</div>
<div class="section" id="optimizing-model-performance">
<h2>Optimizing model performance<a class="headerlink" href="#optimizing-model-performance" title="Permalink to this headline">¶</a></h2>
<p>The <code class="docutils literal notranslate"><span class="pre">classeval</span></code> library can also help in tuning the models performance by examining the effect of the threshold.
After learning a model, and predicting new samples with it, each sample will get a probability belowing to the class.
In case of our two-class approach the simple rule account: <em>P(class-of-interest) = 1-P(not class-of-interest)</em></p>
</div>
</div>
<div class="section" id="evaluation-methods">
<h1>Evaluation methods<a class="headerlink" href="#evaluation-methods" title="Permalink to this headline">¶</a></h1>
<div class="section" id="confusion-matrix">
<h2>Confusion matrix<a class="headerlink" href="#confusion-matrix" title="Permalink to this headline">¶</a></h2>
<p>A confusion matrix is a table that is used to describe the performance of a classification model on a set of test data for which the true values are known.</p>
<p>The function is callable by func:<cite>classeval.confmatrix.eval</cite> and the plot can be created with func:<cite>classeval.confmatrix.plot</cite></p>
<dl class="simple">
<dt>Applicable</dt><dd><ul class="simple">
<li><p>Two-class approach</p></li>
<li><p>multi-class approach</p></li>
</ul>
</dd>
</dl>
</div>
<div class="section" id="roc-auc">
<h2>ROC-AUC<a class="headerlink" href="#roc-auc" title="Permalink to this headline">¶</a></h2>
<p>The Area Under The Curve (AUC) and Receiver Operating Characteristics curve (ROC) are one of the most important evaluation metrics for checking any classification model’s performance.
The goal of the AUC-ROC is to determine the probability curve and degree or measure of separability by using various thresholds settings.
It describes <em>how much</em> the model is capable of distinguishing between the classes.
The higher the AUC, the better the model is at predicting whereas a AUC of 0.5 represents <em>random</em> results.</p>
<p>In case of a <em>multi-class approach</em>, the AUC is computed using the One-vs-Rest scheme (OvR) and One-vs-One scheme (OvO) schemes.
The multi-class One-vs-One scheme compares every unique pairwise combination of classes. Macro average, and a prevalence-weighted average.
This function is callable via: <a class="reference internal" href="classeval.classeval.html#classeval.classeval.AUC_multiclass" title="classeval.classeval.AUC_multiclass"><code class="xref py py-func docutils literal notranslate"><span class="pre">classeval.classeval.AUC_multiclass()</span></code></a></p>
<p>The function is callable by func:<cite>classeval.ROC.eval</cite> and the plot can be created with func:<cite>classeval.ROC.plot</cite></p>
<dl class="simple">
<dt>Applicable</dt><dd><ul class="simple">
<li><p>Two-class approach</p></li>
<li><p>multi-class approach</p></li>
</ul>
</dd>
</dl>
<p>A perfect score would result in an AUC score=1 and ROC curve like this:</p>
<div class="figure align-default" id="roc-best">
<img alt="_images/ROC_best.png" src="_images/ROC_best.png" />
</div>
</div>
<div class="section" id="cap">
<h2>CAP<a class="headerlink" href="#cap" title="Permalink to this headline">¶</a></h2>
<p>The CAP Curve analyse how to effectively identify all data points of a given class using minimum number of tries.
This function computes Cumulitive Accuracy Profile (CAP) to measure the performance of a classifier.
It ranks the predicted class probabilities (high to low), together with the true values.
With that, it computes the cumsum which is the final line.
A perfect model is one which will detect all class 1.0 data points in the same number of tries as there are class 1.0 data points.</p>
<p>This function is callable with: <a class="reference internal" href="classeval.classeval.html#classeval.classeval.CAP" title="classeval.classeval.CAP"><code class="xref py py-func docutils literal notranslate"><span class="pre">classeval.classeval.CAP()</span></code></a></p>
<dl class="simple">
<dt>Applicable</dt><dd><ul class="simple">
<li><p>Two-class approach</p></li>
</ul>
</dd>
<dt>A perfect score would result in an CAP score=100 and CAP. Note that if the value is more than 90%, it’s a good practice to test for over fitting.</dt><dd><ol class="arabic simple">
<li><p>More than 90%: Too Good to be True</p></li>
<li><p>80% — 90%: Very Good Model</p></li>
<li><p>70% — 80%: Good Model</p></li>
<li><p>60% — 70%: Poor Model</p></li>
<li><p>Less than 60%: Rubbish Model</p></li>
</ol>
</dd>
</dl>
<div class="figure align-default" id="cap-best-model">
<img alt="_images/CAP_best_model.png" src="_images/CAP_best_model.png" />
</div>
</div>
<div class="section" id="average-precision-ap">
<h2>Average Precision (AP)<a class="headerlink" href="#average-precision-ap" title="Permalink to this headline">¶</a></h2>
<p>A better metric in an imbalanced situation is the AUC PR (Area Under the Curve Precision Recall), or also called AP (Average Precision).
If the precision decreases when we increase the recall, it shows that we have to choose a prediction thresold adapted to our needs.
If our goal is to have a high recall, we should set a low prediction thresold that will allow us to detect most of the observations of the positive class, but with a low precision. On the contrary, if we want to be really confident about our predictions but don’t mind about not finding all the positive observations, we should set a high thresold that will get us a high precision and a low recall. In order to know if our model performs better than another classifier, we can simply use the AP metric.
To assess the quality of our model, we can compare it to a simple decision baseline.</p>
<p>Let’s take a random classifier as a baseline here that would predict half of the time 1 and half of the time 0 for the label.
Such a classifier would have a precision of 4.3%, which corresponds to the proportion of positive observations.
For every recall value the precision would stay the same, and this would lead us to an AP of 0.043.
The AP of our model is approximately 0.35, which is more than 8 times higher than the AP of the random method.
This means that our model has a good predictive power.</p>
<p>This function is callable with: <a class="reference internal" href="classeval.classeval.html#classeval.classeval.AP" title="classeval.classeval.AP"><code class="xref py py-func docutils literal notranslate"><span class="pre">classeval.classeval.AP()</span></code></a></p>
<dl class="simple">
<dt>Applicable</dt><dd><ul class="simple">
<li><p>Two-class approach</p></li>
<li><p>Imbalanced classes</p></li>
</ul>
</dd>
</dl>
</div>
<div class="section" id="f1-score">
<h2>F1-score<a class="headerlink" href="#f1-score" title="Permalink to this headline">¶</a></h2>
<p>The F1 score (also F-score or F-measure) is a measure of a test’s accuracy.
It considers both the precision p and the recall <em>r</em> of the test to compute the score: p is the number of correct positive results divided by the number of all positive results returned by the classifier, and <em>r</em> is the number of correct positive results divided by the number of all relevant samples (all samples that should have been identified as positive).</p>
<div class="figure align-default">
<img alt="_images/F1score.svg" src="_images/F1score.svg" /></div>
<dl class="simple">
<dt>Applicable</dt><dd><ul class="simple">
<li><p>Two-class approach</p></li>
</ul>
</dd>
</dl>
</div>
<div class="section" id="kappa">
<h2>Kappa<a class="headerlink" href="#kappa" title="Permalink to this headline">¶</a></h2>
<p>In essence, the kappa statistic is a measure of how closely the instances classified by the machine learning classifier matched the data labeled as ground truth, controlling for the accuracy of a random classifier as measured by the expected accuracy.
In some other cases we might face a problem with imbalanced classes. E.g. we have two classes, say A and B, and A shows up on 5% of the time. Accuracy can be misleading, so we go for measures such as precision and recall. There are ways to combine the two, such as the F-measure, but the F-measure does not have a very good intuitive explanation, other than it being the harmonic mean of precision and recall.
<em>Cohen’s kappa statistic is a very good measure that can handle very well both multi-class and imbalanced class problems.</em></p>
<div class="figure align-default">
<a class="reference internal image-reference" href="_images/cohen_kappa.gif"><img alt="_images/cohen_kappa.gif" src="_images/cohen_kappa.gif" style="width: 147.29999999999998px; height: 52.8px;" /></a>
</div>
<dl class="simple">
<dt>Applicable</dt><dd><ul class="simple">
<li><p>Two-class approach</p></li>
<li><p>Imbalanced classes</p></li>
</ul>
</dd>
</dl>
<p>As an example, suppose we have the following results as depicted in the confusion matrix:</p>
<blockquote>
<div><blockquote>
<div><table class="docutils align-default">
<colgroup>
<col style="width: 35%" />
<col style="width: 30%" />
<col style="width: 35%" />
</colgroup>
<tbody>
<tr class="row-odd"><td></td>
<td><p>normal</p></td>
<td><p>defect</p></td>
</tr>
<tr class="row-even"><td><p>normal</p></td>
<td><p>22</p></td>
<td><p>9</p></td>
</tr>
<tr class="row-odd"><td><p>defect</p></td>
<td><p>7</p></td>
<td><p>13</p></td>
</tr>
</tbody>
</table>
</div></blockquote>
<ul class="simple">
<li><p>Ground truth: normal (29), defect (22)</p></li>
<li><p>Machine Learning Classifier: normal (31), defect (20)</p></li>
<li><p>Total: (51)</p></li>
<li><p>Observed Accuracy: ((22 + 13) / 51) = 0.69</p></li>
<li><p>Expected Accuracy: ((29 * 31 / 51) + (22 * 20 / 51)) / 51 = 0.51</p></li>
<li><p><em>Kappa</em>: (0.69 - 0.51) / (1 - 0.51) = 0.37</p></li>
</ul>
</div></blockquote>
<p><em>Kappa values below 0 are possible, Cohen notes they are unlikely in practice.</em></p>
</div>
<div class="section" id="mcc">
<h2>MCC<a class="headerlink" href="#mcc" title="Permalink to this headline">¶</a></h2>
<p><em>MCC is extremely good metric for the **imbalanced*</em> classification.*</p>
<dl class="simple">
<dt>Score Ranges between [−1,1], where:</dt><dd><ul class="simple">
<li><p>1 : Perfect prediction</p></li>
<li><p>0 : Random prediction</p></li>
<li><p>−1: Total disagreement between predicted scores and true labels values.</p></li>
</ul>
</dd>
<dt>Applicable</dt><dd><ul class="simple">
<li><p>Two-class approach</p></li>
<li><p>Imbalanced classes</p></li>
</ul>
</dd>
</dl>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="Plots.html" class="btn btn-neutral float-right" title="Eval" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="Installation.html" class="btn btn-neutral float-left" title="Quickstart" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2020, Erdogan Taskesen

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>