

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Methods &mdash; classeval classeval documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/language_data.js"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Eval" href="Plots.html" />
    <link rel="prev" title="Quickstart" href="Installation.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home"> classeval
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Installation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="Installation.html">Quickstart</a></li>
<li class="toctree-l1"><a class="reference internal" href="Installation.html#installation">Installation</a></li>
</ul>
<p class="caption"><span class="caption-text">Methods</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">Methods</a></li>
<li class="toctree-l1"><a class="reference internal" href="#optimizing-model-performance">Optimizing model performance</a></li>
<li class="toctree-l1"><a class="reference internal" href="#confusion-matrix">Confusion matrix</a></li>
<li class="toctree-l1"><a class="reference internal" href="#two-class-evaluation">Two-class evaluation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#roc-auc">ROC-AUC</a></li>
<li class="toctree-l2"><a class="reference internal" href="#cap">CAP</a></li>
<li class="toctree-l2"><a class="reference internal" href="#average-precision-ap">Average Precision (AP)</a></li>
<li class="toctree-l2"><a class="reference internal" href="#f1-score">F1-score</a></li>
<li class="toctree-l2"><a class="reference internal" href="#kappa">Kappa</a></li>
<li class="toctree-l2"><a class="reference internal" href="#mcc">MCC</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="#multi-class-evaluation">Multi-class evaluation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#auc-multiclass">AUC multiclass</a></li>
</ul>
</li>
</ul>
<p class="caption"><span class="caption-text">Plots</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="Plots.html">Eval</a></li>
<li class="toctree-l1"><a class="reference internal" href="Plots.html#roc-auc">ROC-AUC</a></li>
<li class="toctree-l1"><a class="reference internal" href="Plots.html#cap">CAP</a></li>
<li class="toctree-l1"><a class="reference internal" href="Plots.html#ap">AP</a></li>
<li class="toctree-l1"><a class="reference internal" href="Plots.html#confusion-matrix">Confusion matrix</a></li>
<li class="toctree-l1"><a class="reference internal" href="Plots.html#probability-plot">Probability Plot</a></li>
</ul>
<p class="caption"><span class="caption-text">Examples</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="Examples.html">Examples two-class model</a></li>
<li class="toctree-l1"><a class="reference internal" href="Examples.html#examples-multi-class-model">Examples multi-class model</a></li>
<li class="toctree-l1"><a class="reference internal" href="Examples.html#performance-tweaking">Performance tweaking</a></li>
</ul>
<p class="caption"><span class="caption-text">Code Documentation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="Coding quality.html">Coding quality</a></li>
<li class="toctree-l1"><a class="reference internal" href="classeval.classeval.html">API References</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">classeval</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html">Docs</a> &raquo;</li>
        
      <li>Methods</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/Methods.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <hr class="docutils" id="code-directive" />
<div class="section" id="methods">
<h1>Methods<a class="headerlink" href="#methods" title="Permalink to this headline">¶</a></h1>
<p>The <code class="docutils literal notranslate"><span class="pre">classeval</span></code> library contains various measures to estimate the models performance.
The main function to evaluated models performance is the function <a class="reference internal" href="classeval.classeval.html#classeval.classeval.eval" title="classeval.classeval.eval"><code class="xref py py-func docutils literal notranslate"><span class="pre">classeval.classeval.eval()</span></code></a>. This function automatically determines whether your trained model is based on a <strong>two-class</strong> or <strong>multi-class</strong> approach. If desired, it is possible to directly use the two-class evalution method using <a class="reference internal" href="classeval.classeval.html#classeval.classeval.eval_twoclass" title="classeval.classeval.eval_twoclass"><code class="xref py py-func docutils literal notranslate"><span class="pre">classeval.classeval.eval_twoclass()</span></code></a> and for multi-class: <a class="reference internal" href="classeval.classeval.html#classeval.classeval.eval_multiclass" title="classeval.classeval.eval_multiclass"><code class="xref py py-func docutils literal notranslate"><span class="pre">classeval.classeval.eval_multiclass()</span></code></a>.</p>
</div>
<div class="section" id="optimizing-model-performance">
<h1>Optimizing model performance<a class="headerlink" href="#optimizing-model-performance" title="Permalink to this headline">¶</a></h1>
<p>the <code class="docutils literal notranslate"><span class="pre">classeval</span></code> library can also help in tuning the models performance as the the threshold being used can be adjusted. After learning a model, and predicting new samples with it, each sample will get a probability belowing to the class. In case of our two-class approach the simple rule account: <strong>P(class-of-interest) = 1-P(class-rest)</strong></p>
</div>
<div class="section" id="confusion-matrix">
<h1>Confusion matrix<a class="headerlink" href="#confusion-matrix" title="Permalink to this headline">¶</a></h1>
<p>A confusion matrix is a table that is used to describe the performance of a classification model (or “classifier”) on a set of test data for which the true values are known. It is suitable for both <strong>two-class</strong> and <strong>multi-class</strong> approach.</p>
</div>
<div class="section" id="two-class-evaluation">
<h1>Two-class evaluation<a class="headerlink" href="#two-class-evaluation" title="Permalink to this headline">¶</a></h1>
<p>Two-class models are trained models whos results are based on two classes. The results can be derived from image-recognition, network-analysis, sensor data or any other type of data. The output of the model should result at least:</p>
<blockquote>
<div><ul class="simple">
<li><p>y_true : The true class label</p></li>
<li><p>y_pred : Predicted class label</p></li>
<li><p>y_proba : Probability of the predicted class label</p></li>
</ul>
</div></blockquote>
<p>With this information, various statistics can be performed that are described below:</p>
<div class="section" id="roc-auc">
<h2>ROC-AUC<a class="headerlink" href="#roc-auc" title="Permalink to this headline">¶</a></h2>
<p>The Area Under The Curve (AUC) and Receiver Operating Characteristics curve (ROC) are one of the most important evaluation metrics for checking any classification model’s performance. The goal of the AUC-ROC is to determine the probability curve and degree or measure of separability by using various thresholds settings. It describes <em>how much</em> the model is capable of distinguishing between the classes. The higher the AUC, the better the model is at predicting whereas a AUC of 0.5 represents <em>random</em> results.</p>
<p>A perfect score would result in an AUC score=1 and ROC curve like this:</p>
<div class="figure align-default" id="roc-best">
<img alt="_images/ROC_best.png" src="_images/ROC_best.png" />
</div>
<p>The ROC plot with the AUC score can be evaluated by func:<cite>classeval.ROC.eval</cite> and the plot can be created with func:<cite>classeval.ROC.plot</cite></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># ROC evaluation</span>
<span class="n">out_ROC</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">ROC</span><span class="o">.</span><span class="n">eval</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_proba</span><span class="p">,</span> <span class="n">y_score</span><span class="p">)</span>
<span class="c1"># Make plot</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">ROC</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">out_ROC</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="cap">
<h2>CAP<a class="headerlink" href="#cap" title="Permalink to this headline">¶</a></h2>
<p>The CAP Curve analyse how to effectively identify all data points of a given class using minimum number of tries. This function computes Cumulitive Accuracy Profile (CAP) to measure the performance of a classifier. It ranks the predicted class probabilities (high to low), together with the true values. With that, it computes the cumsum which is the final line.
A perfect model is one which will detect all class 1.0 data points in the same number of tries as there are class 1.0 data points. This function is callable via: <a class="reference internal" href="classeval.classeval.html#classeval.classeval.CAP" title="classeval.classeval.CAP"><code class="xref py py-func docutils literal notranslate"><span class="pre">classeval.classeval.CAP()</span></code></a></p>
</div>
<div class="section" id="average-precision-ap">
<h2>Average Precision (AP)<a class="headerlink" href="#average-precision-ap" title="Permalink to this headline">¶</a></h2>
<p>A better metric in an imbalanced situation is the AUC PR (Area Under the Curve Precision Recall), or also called AP (Average Precision). If the precision decreases when we increase the recall, it shows that we have to choose a prediction thresold adapted to our needs.
If our goal is to have a high recall, we should set a low prediction thresold that will allow us to detect most of the observations of the positive class, but with a low precision. On the contrary, if we want to be really confident about our predictions but don’t mind about not finding all the positive observations, we should set a high thresold that will get us a high precision and a low recall. In order to know if our model performs better than another classifier, we can simply use the AP metric. To assess the quality of our model, we can compare it to a simple decision baseline.</p>
<p>Let’s take a random classifier as a baseline here that would predict half of the time 1 and half of the time 0 for the label. Such a classifier would have a precision of 4.3%, which corresponds to the proportion of positive observations. For every recall value the precision would stay the same, and this would lead us to an AP of 0.043. The AP of our model is approximately 0.35, which is more than 8 times higher than the AP of the random method. This means that our model has a good predictive power.</p>
<p>This function is callable via: <a class="reference internal" href="classeval.classeval.html#classeval.classeval.AP" title="classeval.classeval.AP"><code class="xref py py-func docutils literal notranslate"><span class="pre">classeval.classeval.AP()</span></code></a></p>
</div>
<div class="section" id="f1-score">
<h2>F1-score<a class="headerlink" href="#f1-score" title="Permalink to this headline">¶</a></h2>
<p>The F1 score (also F-score or F-measure) is a measure of a test’s accuracy. It considers both the precision p and the recall r of the test to compute the score: p is the number of correct positive results divided by the number of all positive results returned by the classifier, and r is the number of correct positive results divided by the number of all relevant samples (all samples that should have been identified as positive).</p>
<div class="figure align-default">
<img alt="_images/F1score.svg" src="_images/F1score.svg" /></div>
</div>
<div class="section" id="kappa">
<h2>Kappa<a class="headerlink" href="#kappa" title="Permalink to this headline">¶</a></h2>
<p>In essence, the kappa statistic is a measure of how closely the instances classified by the machine learning classifier matched the data labeled as ground truth, controlling for the accuracy of a random classifier as measured by the expected accuracy.</p>
<p>In some other cases we might face a problem with imbalanced classes. E.g. we have two classes, say A and B, and A shows up on 5% of the time. Accuracy can be misleading, so we go for measures such as precision and recall. There are ways to combine the two, such as the F-measure, but the F-measure does not have a very good intuitive explanation, other than it being the harmonic mean of precision and recall.</p>
<p><em>Cohen’s kappa statistic is a very good measure that can handle very well both multi-class and imbalanced class problems.</em></p>
<div class="figure align-default">
<a class="reference internal image-reference" href="_images/cohen_kappa.gif"><img alt="_images/cohen_kappa.gif" src="_images/cohen_kappa.gif" style="width: 147.29999999999998px; height: 52.8px;" /></a>
</div>
<p>As an example, suppose we have the following results as depicted in the confusion matrix:</p>
<blockquote>
<div><blockquote>
<div><table class="docutils align-default">
<colgroup>
<col style="width: 35%" />
<col style="width: 30%" />
<col style="width: 35%" />
</colgroup>
<tbody>
<tr class="row-odd"><td></td>
<td><p>normal</p></td>
<td><p>defect</p></td>
</tr>
<tr class="row-even"><td><p>normal</p></td>
<td><p>22</p></td>
<td><p>9</p></td>
</tr>
<tr class="row-odd"><td><p>defect</p></td>
<td><p>7</p></td>
<td><p>13</p></td>
</tr>
</tbody>
</table>
</div></blockquote>
<ul class="simple">
<li><p>Ground truth: normal (29), defect (22)</p></li>
<li><p>Machine Learning Classifier: normal (31), defect (20)</p></li>
<li><p>Total: (51)</p></li>
<li><p>Observed Accuracy: ((22 + 13) / 51) = 0.69</p></li>
<li><p>Expected Accuracy: ((29 * 31 / 51) + (22 * 20 / 51)) / 51 = 0.51</p></li>
<li><p><em>Kappa</em>: (0.69 - 0.51) / (1 - 0.51) = 0.37</p></li>
</ul>
</div></blockquote>
<p><em>Kappa values below 0 are possible, Cohen notes they are unlikely in practice.</em></p>
</div>
<div class="section" id="mcc">
<h2>MCC<a class="headerlink" href="#mcc" title="Permalink to this headline">¶</a></h2>
<p><em>MCC is extremely good metric for the **imbalanced*</em> classification.*</p>
<dl class="simple">
<dt>Score Ranges between [−1,1]:</dt><dd><p>1 : Perfect prediction
0 : Random prediction
−1: Total disagreement between predicted scores and true labels values.</p>
</dd>
</dl>
</div>
</div>
<div class="section" id="multi-class-evaluation">
<h1>Multi-class evaluation<a class="headerlink" href="#multi-class-evaluation" title="Permalink to this headline">¶</a></h1>
<div class="section" id="auc-multiclass">
<h2>AUC multiclass<a class="headerlink" href="#auc-multiclass" title="Permalink to this headline">¶</a></h2>
<p>Calculate the AUC using the One-vs-Rest scheme (OvR) and One-vs-One scheme (OvO) schemes.
The multi-class One-vs-One scheme compares every unique pairwise combination of classes. Macro average, and a prevalence-weighted average. This function is callable via: <a class="reference internal" href="classeval.classeval.html#classeval.classeval.AUC_multiclass" title="classeval.classeval.AUC_multiclass"><code class="xref py py-func docutils literal notranslate"><span class="pre">classeval.classeval.AUC_multiclass()</span></code></a></p>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="Plots.html" class="btn btn-neutral float-right" title="Eval" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="Installation.html" class="btn btn-neutral float-left" title="Quickstart" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2020, Erdogan Taskesen

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>